{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jknjkajk.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "za2glbPeDgDZ",
        "colab_type": "code",
        "outputId": "00f1ce1b-bc07-444c-cf95-988af6fb96ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "%mkdir ../data\n",
        "!wget -O ../data/aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -zxf ../data/aclImdb_v1.tar.gz -C ../data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-14 17:41:02--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘../data/aclImdb_v1.tar.gz’\n",
            "\n",
            "../data/aclImdb_v1. 100%[===================>]  80.23M  21.4MB/s    in 5.1s    \n",
            "\n",
            "2020-06-14 17:41:07 (15.7 MB/s) - ‘../data/aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba6VKjQYDmx7",
        "colab_type": "code",
        "outputId": "8dac3ab0-4c0a-4ec8-e1dd-5c41394a4b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def read_imdb_data(data_dir='../data/aclImdb'):\n",
        "    data = {}\n",
        "    labels = {}\n",
        "    \n",
        "    for data_type in ['train', 'test']:\n",
        "        data[data_type] = {}\n",
        "        labels[data_type] = {}\n",
        "        \n",
        "        for sentiment in ['pos', 'neg']:\n",
        "            data[data_type][sentiment] = []\n",
        "            labels[data_type][sentiment] = []\n",
        "            \n",
        "            path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
        "            files = glob.glob(path)\n",
        "            \n",
        "            for f in files:\n",
        "                with open(f) as review:\n",
        "                    data[data_type][sentiment].append(review.read())\n",
        "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
        "                    \n",
        "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
        "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
        "                \n",
        "    return data, labels\n",
        "data, labels = read_imdb_data()\n",
        "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
        "            len(data['train']['pos']), len(data['train']['neg']),\n",
        "            len(data['test']['pos']), len(data['test']['neg'])))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba7a892PDqRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "def prepare_imdb_data(data, labels):\n",
        "   \n",
        "    data_train = data['train']['pos'] + data['train']['neg']\n",
        "    data_test = data['test']['pos'] + data['test']['neg']\n",
        "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
        "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
        "\n",
        "    data_train, labels_train = shuffle(data_train, labels_train)\n",
        "    data_test, labels_test = shuffle(data_test, labels_test)\n",
        " \n",
        "    return data_train, data_test, labels_train, labels_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fTbV3_OEJc5",
        "colab_type": "code",
        "outputId": "17c61085-d2b5-4099-daf7-4a2c5a92d791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X, test_X, train_y, test_y = prepare_imdb_data(data, labels)\n",
        "print(\"IMDb reviews (combined): train = {}, test = {}\".format(len(train_X), len(test_X)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IMDb reviews (combined): train = 25000, test = 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dIDxGtSEN9B",
        "colab_type": "code",
        "outputId": "95e4d616-113c-4365-bc93-fd6908b37ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(train_X[1])\n",
        "print(train_y[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After witnessing his wife (Linda Hoffman) engaging in sexual acts with the pool boy, the already somewhat unstable dentist Dr. Feinstone (Corbin Bernsen) completely snaps which means deep trouble for his patients.<br /><br />This delightful semi-original and entertaining horror flick from director Brian Yuzna was a welcome change of pace from the usual horror twaddle that was passed out in the late Nineties. Although The Dentist' is intended to be a cheesy, fun little film, Yuzna ensures that the movie delivers the shocks and thrills that many more serious movies attempt to dispense. Despite suffering somewhat from the lack of background on the central characters, and thus allowing events that should have been built up to take place over a couple of days, the movie is intriguing, generally well scripted and well paced which allows the viewer to maintain interest, even during the more ludicrous of moments. The Dentist' suffers, on occasion, from dragging but unlike the much inferior 1998 sequel, there are only sporadic uninteresting moments, and in general the movie follows itself nicely.<br /><br />Corbin Bernsen was very convincing in the role of the sadistic, deranged and perfectionist Dr. Alan Feinstone. The way Bernsen is able to credibly recite his lines, especially with regards to the foulness and immorality of sex (particularly fellatio), is something short of marvellous. While many actors may have trouble portraying a cleanliness obsessed psycho without it coming off as too cheesy or ridiculous, Bernsen seems to truly fit the personality of the character he attempts to portray and thus makes the film all that more enjoyable. Had The Dentist' not been intended to be a fun, almost comical, horror movie, Bernsen's performance would probably have been much more powerful. Sadly, the rest of the cast (including a pre-fame Mark Ruffalo) failed to put in very good performances and although the movie was not really damaged by this, stronger performances could have added more credibility to the flick.<br /><br />The Dentist' is not a horror film that is meant to be taken seriously but is certainly enjoyable, particularly (I would presume) for fans of cheesy horror. Those who became annoyed at the number of Scream' (1996) clones from the late Nineties may very well find this a refreshing change, as I did. A seldom dull and generally well paced script as well as some proficient direction helps to make The Dentist' one of the more pleasurable cheesy horrors from the 1990's. On top of this we are presented with some particularly grizly and (on the whole) realistic scenes of dental torture, which should keep most gorehounds happy. Far from perfect but far from bad as well, The Dentist' is a flick that is easily worth watching at least once. My rating for The Dentist'  6.5/10.\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3P1aD9JERtt",
        "colab_type": "code",
        "outputId": "b6f26a00-2a3a-416b-f4d6-3bcb8847c534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def review_to_words(review):\n",
        "    nltk.download(\"stopwords\", quiet=True)\n",
        "    stemmer = PorterStemmer()\n",
        "    \n",
        "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
        "    words = text.split() # Split string into words\n",
        "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
        "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
        "    \n",
        "    return words\n",
        "review_to_words(train_X[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wit',\n",
              " 'wife',\n",
              " 'linda',\n",
              " 'hoffman',\n",
              " 'engag',\n",
              " 'sexual',\n",
              " 'act',\n",
              " 'pool',\n",
              " 'boy',\n",
              " 'alreadi',\n",
              " 'somewhat',\n",
              " 'unstabl',\n",
              " 'dentist',\n",
              " 'dr',\n",
              " 'feinston',\n",
              " 'corbin',\n",
              " 'bernsen',\n",
              " 'complet',\n",
              " 'snap',\n",
              " 'mean',\n",
              " 'deep',\n",
              " 'troubl',\n",
              " 'patient',\n",
              " 'delight',\n",
              " 'semi',\n",
              " 'origin',\n",
              " 'entertain',\n",
              " 'horror',\n",
              " 'flick',\n",
              " 'director',\n",
              " 'brian',\n",
              " 'yuzna',\n",
              " 'welcom',\n",
              " 'chang',\n",
              " 'pace',\n",
              " 'usual',\n",
              " 'horror',\n",
              " 'twaddl',\n",
              " 'pass',\n",
              " 'late',\n",
              " 'nineti',\n",
              " 'although',\n",
              " 'dentist',\n",
              " 'intend',\n",
              " 'cheesi',\n",
              " 'fun',\n",
              " 'littl',\n",
              " 'film',\n",
              " 'yuzna',\n",
              " 'ensur',\n",
              " 'movi',\n",
              " 'deliv',\n",
              " 'shock',\n",
              " 'thrill',\n",
              " 'mani',\n",
              " 'seriou',\n",
              " 'movi',\n",
              " 'attempt',\n",
              " 'dispens',\n",
              " 'despit',\n",
              " 'suffer',\n",
              " 'somewhat',\n",
              " 'lack',\n",
              " 'background',\n",
              " 'central',\n",
              " 'charact',\n",
              " 'thu',\n",
              " 'allow',\n",
              " 'event',\n",
              " 'built',\n",
              " 'take',\n",
              " 'place',\n",
              " 'coupl',\n",
              " 'day',\n",
              " 'movi',\n",
              " 'intrigu',\n",
              " 'gener',\n",
              " 'well',\n",
              " 'script',\n",
              " 'well',\n",
              " 'pace',\n",
              " 'allow',\n",
              " 'viewer',\n",
              " 'maintain',\n",
              " 'interest',\n",
              " 'even',\n",
              " 'ludicr',\n",
              " 'moment',\n",
              " 'dentist',\n",
              " 'suffer',\n",
              " 'occas',\n",
              " 'drag',\n",
              " 'unlik',\n",
              " 'much',\n",
              " 'inferior',\n",
              " '1998',\n",
              " 'sequel',\n",
              " 'sporad',\n",
              " 'uninterest',\n",
              " 'moment',\n",
              " 'gener',\n",
              " 'movi',\n",
              " 'follow',\n",
              " 'nice',\n",
              " 'corbin',\n",
              " 'bernsen',\n",
              " 'convinc',\n",
              " 'role',\n",
              " 'sadist',\n",
              " 'derang',\n",
              " 'perfectionist',\n",
              " 'dr',\n",
              " 'alan',\n",
              " 'feinston',\n",
              " 'way',\n",
              " 'bernsen',\n",
              " 'abl',\n",
              " 'credibl',\n",
              " 'recit',\n",
              " 'line',\n",
              " 'especi',\n",
              " 'regard',\n",
              " 'foul',\n",
              " 'immor',\n",
              " 'sex',\n",
              " 'particularli',\n",
              " 'fellatio',\n",
              " 'someth',\n",
              " 'short',\n",
              " 'marvel',\n",
              " 'mani',\n",
              " 'actor',\n",
              " 'may',\n",
              " 'troubl',\n",
              " 'portray',\n",
              " 'cleanli',\n",
              " 'obsess',\n",
              " 'psycho',\n",
              " 'without',\n",
              " 'come',\n",
              " 'cheesi',\n",
              " 'ridicul',\n",
              " 'bernsen',\n",
              " 'seem',\n",
              " 'truli',\n",
              " 'fit',\n",
              " 'person',\n",
              " 'charact',\n",
              " 'attempt',\n",
              " 'portray',\n",
              " 'thu',\n",
              " 'make',\n",
              " 'film',\n",
              " 'enjoy',\n",
              " 'dentist',\n",
              " 'intend',\n",
              " 'fun',\n",
              " 'almost',\n",
              " 'comic',\n",
              " 'horror',\n",
              " 'movi',\n",
              " 'bernsen',\n",
              " 'perform',\n",
              " 'would',\n",
              " 'probabl',\n",
              " 'much',\n",
              " 'power',\n",
              " 'sadli',\n",
              " 'rest',\n",
              " 'cast',\n",
              " 'includ',\n",
              " 'pre',\n",
              " 'fame',\n",
              " 'mark',\n",
              " 'ruffalo',\n",
              " 'fail',\n",
              " 'put',\n",
              " 'good',\n",
              " 'perform',\n",
              " 'although',\n",
              " 'movi',\n",
              " 'realli',\n",
              " 'damag',\n",
              " 'stronger',\n",
              " 'perform',\n",
              " 'could',\n",
              " 'ad',\n",
              " 'credibl',\n",
              " 'flick',\n",
              " 'dentist',\n",
              " 'horror',\n",
              " 'film',\n",
              " 'meant',\n",
              " 'taken',\n",
              " 'serious',\n",
              " 'certainli',\n",
              " 'enjoy',\n",
              " 'particularli',\n",
              " 'would',\n",
              " 'presum',\n",
              " 'fan',\n",
              " 'cheesi',\n",
              " 'horror',\n",
              " 'becam',\n",
              " 'annoy',\n",
              " 'number',\n",
              " 'scream',\n",
              " '1996',\n",
              " 'clone',\n",
              " 'late',\n",
              " 'nineti',\n",
              " 'may',\n",
              " 'well',\n",
              " 'find',\n",
              " 'refresh',\n",
              " 'chang',\n",
              " 'seldom',\n",
              " 'dull',\n",
              " 'gener',\n",
              " 'well',\n",
              " 'pace',\n",
              " 'script',\n",
              " 'well',\n",
              " 'profici',\n",
              " 'direct',\n",
              " 'help',\n",
              " 'make',\n",
              " 'dentist',\n",
              " 'one',\n",
              " 'pleasur',\n",
              " 'cheesi',\n",
              " 'horror',\n",
              " '1990',\n",
              " 'top',\n",
              " 'present',\n",
              " 'particularli',\n",
              " 'grizli',\n",
              " 'whole',\n",
              " 'realist',\n",
              " 'scene',\n",
              " 'dental',\n",
              " 'tortur',\n",
              " 'keep',\n",
              " 'gorehound',\n",
              " 'happi',\n",
              " 'far',\n",
              " 'perfect',\n",
              " 'far',\n",
              " 'bad',\n",
              " 'well',\n",
              " 'dentist',\n",
              " 'flick',\n",
              " 'easili',\n",
              " 'worth',\n",
              " 'watch',\n",
              " 'least',\n",
              " 'rate',\n",
              " 'dentist',\n",
              " '6',\n",
              " '5',\n",
              " '10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an8UPXrTEY3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "cache_dir = os.path.join(\"../cache\", \"sentiment_analysis\") \n",
        "os.makedirs(cache_dir, exist_ok=True)  \n",
        "\n",
        "def preprocess_data(data_train, data_test, labels_train, labels_test,\n",
        "                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
        " \n",
        "    cache_data = None\n",
        "    if cache_file is not None:\n",
        "        try:\n",
        "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
        "                cache_data = pickle.load(f)\n",
        "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
        "        except:\n",
        "            pass  \n",
        "    if cache_data is None:\n",
        "        words_train = [review_to_words(review) for review in data_train]\n",
        "        words_test = [review_to_words(review) for review in data_test]\n",
        "\n",
        "        if cache_file is not None:\n",
        "            cache_data = dict(words_train=words_train, words_test=words_test,\n",
        "                              labels_train=labels_train, labels_test=labels_test)\n",
        "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
        "                pickle.dump(cache_data, f)\n",
        "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
        "    else:\n",
        "        words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
        "                cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
        "    \n",
        "    return words_train, words_test, labels_train, labels_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Vvjax_EeNd",
        "colab_type": "code",
        "outputId": "66ae5ce2-9212-432d-a3cb-6600c61a3a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X, test_X, train_y, test_y = preprocess_data(train_X, test_X, train_y, test_y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote preprocessed data to cache file: preprocessed_data.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtUmTnyFEhiy",
        "colab_type": "code",
        "outputId": "f22bd4ec-a301-4130-ccf4-b4eb7cbb69c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(train_X[0])\n",
        "train_y[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bell', 'book', 'candl', 'releas', 'decemb', '1958', 'featur', 'jame', 'stewart', 'kim', 'novak', 'jack', 'lemmon', 'erni', 'kovak', 'film', 'jame', 'stewart', 'kim', 'novak', 'second', 'screen', 'pair', 'alfr', 'hitchcock', 'classic', 'vertigo', 'releas', 'earlier', 'year', 'stewart', 'last', 'film', 'romant', 'lead', 'deem', 'old', 'age', '50', 'play', 'sort', 'part', 'anymor', 'movi', 'witch', 'play', 'kim', 'novak', 'attract', 'mortal', 'play', 'jame', 'stewart', 'put', 'spell', 'fall', 'head', 'heel', 'love', 'enjoy', 'movi', 'cast', 'movi', 'time', 'moder', 'success', 'nomin', 'golden', 'globe', 'best', 'movi', 'comedi', 'gimmeclass']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYEY6N6wElHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try1=[]\n",
        "for i in train_X:\n",
        "  try1.append(\" \".join(i))\n",
        "\n",
        "try2=[]\n",
        "for i in test_X:\n",
        "  try2.append(\" \".join(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd-ZHcuHEvOn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "acc76151-7f6f-4930-eea2-ac289a78d3a0"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "\n",
        "def extract_BoW_features(words_train, words_test, vocabulary_size=10000,\n",
        "                         cache_dir=cache_dir, cache_file=\"bow_features.pkl\"):\n",
        "       \n",
        "    cache_data = None\n",
        "    if cache_file is not None:\n",
        "        try:\n",
        "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
        "                cache_data = joblib.load(f)\n",
        "            print(\"Read features from cache file:\", cache_file)\n",
        "        except:\n",
        "            pass  \n",
        "    if cache_data is None:\n",
        "        vectorizer = CountVectorizer(max_features=vocabulary_size)\n",
        "        features_train = vectorizer.fit_transform(words_train).toarray()\n",
        "        features_test = vectorizer.transform(words_test).toarray()\n",
        "        if cache_file is not None:\n",
        "            vocabulary = vectorizer.vocabulary_\n",
        "            cache_data = dict(features_train=features_train, features_test=features_test,\n",
        "                             vocabulary=vocabulary)\n",
        "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
        "                joblib.dump(cache_data, f)\n",
        "            print(\"Wrote features to cache file:\", cache_file)\n",
        "    else:\n",
        "        features_train, features_test, vocabulary = (cache_data['features_train'],\n",
        "                cache_data['features_test'], cache_data['vocabulary'])\n",
        "    \n",
        "    # Return both the extracted features as well as the vocabulary\n",
        "    return features_train, features_test, vocabulary"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxYsXA0yJw7o",
        "colab_type": "code",
        "outputId": "09fe7bff-e3ed-4020-c7d9-dd32a6e771c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X, test_X, vocabulary = extract_BoW_features(try1, try2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote features to cache file: bow_features.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN3EVhQhKBEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "val_X = pd.DataFrame(train_X[:10000])\n",
        "train_X = pd.DataFrame(train_X[10000:])\n",
        "val_y = pd.DataFrame(train_y[:10000])\n",
        "train_y = pd.DataFrame(train_y[10000:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tIdZcQQKGQ8",
        "colab_type": "code",
        "outputId": "c2b475d1-ee38-42f4-e836-cd1adc660ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "test_X"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ3Kae2HKLaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '../data/sentiment_web_app'\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ8mhMfkKOYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(test_X).to_csv( ('test.csv'), header=False, index=False)\n",
        "\n",
        "pd.concat([val_y, val_X], axis=1).to_csv(('validation.csv'), header=False, index=False)\n",
        "pd.concat([train_y, train_X], axis=1).to_csv(('train.csv'), header=False, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqHXoMvDKcuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_location = pd.read_csv( 'test.csv')\n",
        "val_location = pd.read_csv('validation.csv')\n",
        "train_location = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XURcDFQL4q7",
        "colab_type": "code",
        "outputId": "e869bae6-f616-464c-ea8b-bef48d571b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train_y"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0\n",
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "...   ..\n",
              "14995  1\n",
              "14996  1\n",
              "14997  1\n",
              "14998  1\n",
              "14999  1\n",
              "\n",
              "[15000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txo8D_XwMG6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob, os, string, re, spacy\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_tOkrIdMx52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = LogisticRegression(solver = 'lbfgs', n_jobs = -1)\n",
        "LR.fit(train_X, train_y)\n",
        "LR_clf = LR.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg9TIsjQMXzJ",
        "colab_type": "code",
        "outputId": "c5ea4866-1444-4ea7-d240-52d993be6ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LR.score(train_X, train_y)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9948"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcdMr3i8PFdg",
        "colab_type": "code",
        "outputId": "f5a10a85-acd7-4724-a782-bf6f3cdae1e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(test_y, LR_clf)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.84656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2477jZicPcGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSVM = LinearSVC()\n",
        "LSVM.fit(train_X, train_y)\n",
        "LSVM_clf = LSVM.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH3QXjaHPuBD",
        "colab_type": "code",
        "outputId": "e357f24f-555d-4f49-f7bb-49ea50465669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LSVM.score(train_X, train_y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWVJvf2CP3TF",
        "colab_type": "code",
        "outputId": "b3e10a85-e568-4b03-fe0b-d782eea2c7e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(test_y, LSVM_clf)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEUGSX1xP_OQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MNB = MultinomialNB()\n",
        "MNB.fit(train_X, train_y)\n",
        "MNB_clf = MNB.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sev3rLHQW8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a030dd9-9d95-45df-c44a-eefcb999df98"
      },
      "source": [
        "MNB.score(train_X, train_y)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8769333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3XKiRaLQd8B",
        "colab_type": "code",
        "outputId": "42d08c24-a649-4e86-c9cb-a811d612e69e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(test_y, MNB_clf)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82228"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbamMl0mGv9Q",
        "colab_type": "text"
      },
      "source": [
        "**Trying some other parts also**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5XEtj2PHUmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c623348d-5a13-4642-fe3c-22773af6b86e"
      },
      "source": [
        "!wget -O aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -zxf aclImdb_v1.tar.gz "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-14 18:35:52--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  22.3MB/s    in 4.6s    \n",
            "\n",
            "2020-06-14 18:35:56 (17.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt10idQPKUHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob, os, string, re, spacy\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xg1QbcPGuW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pos_files = glob.glob(\"aclImdb/train/pos/*.txt\")\n",
        "train_neg_files = glob.glob(\"aclImdb/train/neg/*.txt\")\n",
        "train_pos_ls = []\n",
        "\n",
        "for i in train_pos_files:\n",
        "    file = open(i, \"r\")\n",
        "    str = file.readline()\n",
        "    clean = re.compile('<.*?>')\n",
        "    str = re.sub(clean, ' ', str)\n",
        "    train_pos_ls.append(str)\n",
        "    \n",
        "train_neg_ls = []\n",
        "for i in train_neg_files:\n",
        "    file = open(i, \"r\")\n",
        "    str = file.readline()\n",
        "    clean = re.compile('<.*?>')\n",
        "    str = re.sub(clean, ' ', str)\n",
        "    train_neg_ls.append(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVgPffeOHIjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "2649dc77-baad-4924-c89c-4cc2aea96772"
      },
      "source": [
        "labels = ['reveiw', 'label']\n",
        "df_train_pos = pd.DataFrame()\n",
        "df_train_pos['review'] = train_pos_ls\n",
        "df_train_pos['label'] = 1\n",
        "df_train_neg = pd.DataFrame()\n",
        "df_train_neg['review'] = train_neg_ls\n",
        "df_train_neg['label'] = 0\n",
        "df_train = pd.concat([df_train_pos , df_train_neg])\n",
        "df_train"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I first saw this film around ten years ago and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cosimo (Luis Guzman) ends up in prison for car...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This movie is a journey through the mind of a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Standard rise to fame tale that has a few high...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I originally saw this movie as a boy at the ol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12495</th>\n",
              "      <td>A response to previous comments made by reside...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12496</th>\n",
              "      <td>A scientist (John Carradine--sadly) finds out ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12497</th>\n",
              "      <td>Revolution is a terrible movie, I don't care i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12498</th>\n",
              "      <td>It's boggles the mind how this movie was nomin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12499</th>\n",
              "      <td>Seldom seen since theatrical release in 1970, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  label\n",
              "0      I first saw this film around ten years ago and...      1\n",
              "1      Cosimo (Luis Guzman) ends up in prison for car...      1\n",
              "2      This movie is a journey through the mind of a ...      1\n",
              "3      Standard rise to fame tale that has a few high...      1\n",
              "4      I originally saw this movie as a boy at the ol...      1\n",
              "...                                                  ...    ...\n",
              "12495  A response to previous comments made by reside...      0\n",
              "12496  A scientist (John Carradine--sadly) finds out ...      0\n",
              "12497  Revolution is a terrible movie, I don't care i...      0\n",
              "12498  It's boggles the mind how this movie was nomin...      0\n",
              "12499  Seldom seen since theatrical release in 1970, ...      0\n",
              "\n",
              "[25000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEdO6f9iHlC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "14edafb9-cf09-44e3-b0e4-04b19746f9cc"
      },
      "source": [
        "test_pos_files = glob.glob(\"aclImdb/test/pos/*.txt\")\n",
        "test_neg_files = glob.glob(\"aclImdb/test/neg/*.txt\")\n",
        "test_pos_ls = []\n",
        "for i in test_pos_files:\n",
        "    file = open(i, \"r\")\n",
        "    str = file.readline()\n",
        "    clean = re.compile('<.*?>')\n",
        "    str = re.sub(clean, ' ', str)\n",
        "    test_pos_ls.append(str)\n",
        "    \n",
        "test_neg_ls = []\n",
        "for i in test_neg_files:\n",
        "    file = open(i, \"r\")\n",
        "    str = file.readline()\n",
        "    clean = re.compile('<.*?>')\n",
        "    str = re.sub(clean, ' ', str)\n",
        "    test_neg_ls.append(str)\n",
        "\n",
        "labels = ['reveiw', 'label']\n",
        "df_test_pos = pd.DataFrame()\n",
        "df_test_pos['review'] = test_pos_ls\n",
        "df_test_pos['label'] = 1\n",
        "df_test_neg = pd.DataFrame()\n",
        "df_test_neg['review'] = test_neg_ls\n",
        "df_test_neg['label'] = 0\n",
        "df_test = pd.concat([df_test_pos , df_test_neg])\n",
        "df_test"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My giving this film a score of 8 is relative t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Probably because this is Columbia's first film...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Genius or utter madness? That depends on your ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This movie was one of the rolling on the floor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1 let's suspend belief for a moment and let's ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12495</th>\n",
              "      <td>I gave this movie 2 instead of 1 just just bec...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12496</th>\n",
              "      <td>I want the 99 minutes of my life back that was...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12497</th>\n",
              "      <td>Ineffectual, molly-coddled, self-pitying, lous...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12498</th>\n",
              "      <td>This film was sourced from my friends mum who ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12499</th>\n",
              "      <td>I'm starting to wonder, after reading some of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  label\n",
              "0      My giving this film a score of 8 is relative t...      1\n",
              "1      Probably because this is Columbia's first film...      1\n",
              "2      Genius or utter madness? That depends on your ...      1\n",
              "3      This movie was one of the rolling on the floor...      1\n",
              "4      1 let's suspend belief for a moment and let's ...      1\n",
              "...                                                  ...    ...\n",
              "12495  I gave this movie 2 instead of 1 just just bec...      0\n",
              "12496  I want the 99 minutes of my life back that was...      0\n",
              "12497  Ineffectual, molly-coddled, self-pitying, lous...      0\n",
              "12498  This film was sourced from my friends mum who ...      0\n",
              "12499  I'm starting to wonder, after reading some of ...      0\n",
              "\n",
              "[25000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34ueqV3MHybr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.to_csv('train1.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLELlYgNJ4ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.to_csv('test2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GaOi__8LN9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "32771e50-b62f-471c-c110-8447c209fc2a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkQbijWvKLVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Define text pre-processing functions\n",
        "lemma = WordNetLemmatizer()\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "            \n",
        "def text_prep(text):\n",
        "    no_punct = [char for char in text if char not in string.punctuation]\n",
        "    text = \"\".join(no_punct)\n",
        "    text = [lemma.lemmatize(text, pos='v') for text in text.lower().split() if text not in stops] \n",
        "    text = \" \".join(text)\n",
        "    return (text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rQA9ghVKj3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b580c511-d87f-4351-aa21-b3eca8158684"
      },
      "source": [
        "df_train['rev'] = df_train['review'].apply(lambda x:text_prep(x))\n",
        "df_train[['rev', 'label']].head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rev</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first saw film around ten years ago think funn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cosimo luis guzman end prison car burglary hes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>movie journey mind screenwriter catch paradoxi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>standard rise fame tale high point number one ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>originally saw movie boy old rialto theatre pa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 rev  label\n",
              "0  first saw film around ten years ago think funn...      1\n",
              "1  cosimo luis guzman end prison car burglary hes...      1\n",
              "2  movie journey mind screenwriter catch paradoxi...      1\n",
              "3  standard rise fame tale high point number one ...      1\n",
              "4  originally saw movie boy old rialto theatre pa...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ATYqDHLnE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5093d6c1-8ced-4e03-f344-0e4b1a5af893"
      },
      "source": [
        "df_test['rev'] = df_test['review'].apply(lambda x:text_prep(x))\n",
        "df_test[['rev', 'label']].head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rev</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>give film score 8 relative featurelength film ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>probably columbias first film color color look...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>genius utter madness depend interpretation fil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>movie one roll floor laugh movies ever see dan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1 let suspend belief moment let stop pretend c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 rev  label\n",
              "0  give film score 8 relative featurelength film ...      1\n",
              "1  probably columbias first film color color look...      1\n",
              "2  genius utter madness depend interpretation fil...      1\n",
              "3  movie one roll floor laugh movies ever see dan...      1\n",
              "4  1 let suspend belief moment let stop pretend c...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uRWL3kCLuRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2cb91a8-4056-4cd4-836a-a7f0ba17b48c"
      },
      "source": [
        "tfidf = TfidfVectorizer(max_features = 1000)\n",
        "x_train = tfidf.fit_transform(df_train['rev'])\n",
        "y_train = df_train['label']\n",
        "x_test = tfidf.transform(df_test['rev'])\n",
        "y_test = df_test['label']\n",
        "x_train.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0i9cRpwMF1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "8535e48a-4cb7-407c-d2e3-3952bf0f05fc"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Convolution1D, Flatten, Dropout, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(1000,) , activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(160, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(120, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(80, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 256)               256256    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               51400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 160)               32160     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 120)               19320     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 80)                9680      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 81        \n",
            "=================================================================\n",
            "Total params: 368,897\n",
            "Trainable params: 368,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3NjVNMNMW93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "bb8414e3-ebb7-43a9-94af-83be9c43384c"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 4s 145us/step - loss: 0.4250 - accuracy: 0.7985\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 3s 112us/step - loss: 0.3095 - accuracy: 0.8722\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 3s 104us/step - loss: 0.2624 - accuracy: 0.8948\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 3s 107us/step - loss: 0.1888 - accuracy: 0.9302\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 3s 106us/step - loss: 0.1173 - accuracy: 0.9571\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 3s 104us/step - loss: 0.0793 - accuracy: 0.9711\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 3s 109us/step - loss: 0.0569 - accuracy: 0.9800\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 3s 111us/step - loss: 0.0415 - accuracy: 0.9851\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 3s 107us/step - loss: 0.0347 - accuracy: 0.9879\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 3s 106us/step - loss: 0.0324 - accuracy: 0.9884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd41f027a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok3Rvz-jMguz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e03c73d2-7db0-4e4e-b261-613e1edd434e"
      },
      "source": [
        "loss, accuracy = model.evaluate(x_train, y_train)\n",
        "print (loss, accuracy)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 58us/step\n",
            "0.005503535429150798 0.9986000061035156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q84Bi0SmMoG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4a35734-afaa-4cec-87f7-584ede601809"
      },
      "source": [
        "predictions = model.predict(x_test)\n",
        "rounded = [round(x[0]) for x in predictions]\n",
        "predictions = rounded\n",
        "score = accuracy_score(y_test ,predictions)\n",
        "print(score)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.84656\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}